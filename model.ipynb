{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add soundfile for audio file writing\n",
    "import soundfile as sf\n",
    "\n",
    "# Set environment variable to disable OneDNN optimizations\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "# Enable mixed precision training for faster computation\n",
    "import tensorflow as tf\n",
    "try:\n",
    "    # Only for GPUs that support it\n",
    "    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "    tf.keras.mixed_precision.set_global_policy(policy)\n",
    "    print(\"Mixed precision training enabled\")\n",
    "except:\n",
    "    print(\"Mixed precision not supported, using default precision\")\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pickle\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to your dataset\n",
    "data_path = r\"D:/Train\" # Base path containing all actor folders\n",
    "\n",
    "# Function to get all actor folders\n",
    "def get_all_actors(base_path):\n",
    "    actor_folders = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]\n",
    "    return actor_folders\n",
    "\n",
    "# Process all actor data in batches\n",
    "def process_all_actors(base_path, batch_size=5):\n",
    "    \"\"\"\n",
    "    Process all actors in the dataset in batches\n",
    "    \n",
    "    Args:\n",
    "        base_path: Path to the dataset containing actor folders\n",
    "        batch_size: Number of actors to process in each batch\n",
    "    \n",
    "    Returns:\n",
    "        Combined metadata dataframe with all actors' data\n",
    "    \"\"\"\n",
    "    # Get all actor folders\n",
    "    all_actors = get_all_actors(base_path)\n",
    "    print(f\"Found {len(all_actors)} actor folders: {all_actors}\")\n",
    "    \n",
    "    all_metadata = []\n",
    "    \n",
    "    # Process actors in batches\n",
    "    for i in range(0, len(all_actors), batch_size):\n",
    "        batch_actors = all_actors[i:i+batch_size]\n",
    "        print(f\"Processing batch of actors: {batch_actors}\")\n",
    "        \n",
    "        batch_metadata = []\n",
    "        for actor in batch_actors:\n",
    "            actor_path = os.path.join(base_path, actor)\n",
    "            for root, dirs, files in os.walk(actor_path):\n",
    "                for file in files:\n",
    "                    if file.endswith('.wav'):\n",
    "                        file_parts = file.split('-')\n",
    "                        if len(file_parts) >= 7:\n",
    "                            modality = file_parts[0]\n",
    "                            vocal_channel = file_parts[1]\n",
    "                            emotion = file_parts[2]\n",
    "                            intensity = file_parts[3]\n",
    "                            statement = file_parts[4]\n",
    "                            repetition = file_parts[5]\n",
    "                            actor_id = file_parts[6].split('.')[0]\n",
    "                            \n",
    "                            batch_metadata.append({\n",
    "                                'file_path': os.path.join(root, file),\n",
    "                                'modality': modality,\n",
    "                                'vocal_channel': vocal_channel,\n",
    "                                'emotion': emotion,\n",
    "                                'intensity': intensity,\n",
    "                                'statement': statement,\n",
    "                                'repetition': repetition,\n",
    "                                'actor': actor_id,\n",
    "                                'actor_folder': actor\n",
    "                            })\n",
    "        \n",
    "        all_metadata.extend(batch_metadata)\n",
    "        print(f\"Processed {len(batch_metadata)} files from actors {batch_actors}\")\n",
    "    \n",
    "    return pd.DataFrame(all_metadata)\n",
    "\n",
    "# Process all actors and generate metadata\n",
    "print(\"Processing all actor data...\")\n",
    "metadata_df = process_all_actors(data_path)\n",
    "\n",
    "# Check if we have data\n",
    "if len(metadata_df) == 0:\n",
    "    print(f\"No .wav files found in {data_path}. Please check the path and file format.\")\n",
    "else:\n",
    "    # Map emotion codes to emotion names (for RAVDESS dataset)\n",
    "    emotion_mapping = {\n",
    "        '01': 'neutral',\n",
    "        '02': 'calm',\n",
    "        '03': 'happy',\n",
    "        '04': 'sad',\n",
    "        '05': 'angry',\n",
    "        '06': 'fearful',\n",
    "        '07': 'disgust',\n",
    "        '08': 'surprised'\n",
    "    }\n",
    "\n",
    "    # Map emotion codes to names\n",
    "    metadata_df['emotion_label'] = metadata_df['emotion'].map(emotion_mapping)\n",
    "\n",
    "    # Display basic information about the dataset\n",
    "    print(f\"Total number of audio files: {len(metadata_df)}\")\n",
    "    print(f\"Number of unique speakers: {metadata_df['actor'].nunique()}\")\n",
    "    print(f\"Actor folders found: {metadata_df['actor_folder'].unique()}\")\n",
    "    print(f\"Emotions in the dataset: {metadata_df['emotion_label'].unique()}\")\n",
    "\n",
    "    # Display distribution of emotions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='emotion_label', data=metadata_df)\n",
    "    plt.title('Distribution of Emotions in the Dataset')\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Also visualize the distribution by actor\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.countplot(x='actor_folder', data=metadata_df)\n",
    "    plt.title('Distribution of Audio Files by Actor')\n",
    "    plt.xlabel('Actor')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# Enhanced feature extraction for better accuracy with minimal time cost\n",
    "def extract_features(file_path, max_pad_len=64):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=22050) # Load audio file with specified sample rate\n",
    "        y = librosa.effects.preemphasis(y, coef=0.97) # Pre-emphasis filter for better frequency response\n",
    "        y, _ = librosa.effects.trim(y, top_db=25)  # Trim silence from the beginning and end\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20, n_fft=1024, hop_length=512) \n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)  \n",
    "        \n",
    "        # Additional spectral features for emotion recognition\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr, n_bands=6)\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.85) \n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        \n",
    "        # Add basic pitch-related feature which is critical for emotion\n",
    "        harmonic = librosa.effects.harmonic(y)\n",
    "        chroma = librosa.feature.chroma_stft(y=harmonic, sr=sr, n_chroma=12) \n",
    "        \n",
    "        # Function to Pad or truncate features\n",
    "        def pad_trunc(feature, max_len):\n",
    "            pad_width = max_len - feature.shape[1]\n",
    "            if pad_width > 0:\n",
    "                return np.pad(feature, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "            else:\n",
    "                return feature[:, :max_len]\n",
    "                \n",
    "        # Pad or truncate all features extracted to the same length\n",
    "        mfcc = pad_trunc(mfcc, max_pad_len)\n",
    "        mfcc_delta = pad_trunc(mfcc_delta, max_pad_len)\n",
    "        mfcc_delta2 = pad_trunc(mfcc_delta2, max_pad_len)\n",
    "        spectral_contrast = pad_trunc(spectral_contrast, max_pad_len)\n",
    "        spectral_centroid = pad_trunc(spectral_centroid, max_pad_len)\n",
    "        spectral_bandwidth = pad_trunc(spectral_bandwidth, max_pad_len)\n",
    "        spectral_rolloff = pad_trunc(spectral_rolloff, max_pad_len)\n",
    "        zcr = pad_trunc(zcr, max_pad_len)\n",
    "        chroma = pad_trunc(chroma, max_pad_len)\n",
    "        \n",
    "        # Combine enhanced feature set\n",
    "        features = np.concatenate([\n",
    "            mfcc, \n",
    "            mfcc_delta, \n",
    "            mfcc_delta2,\n",
    "            spectral_contrast, \n",
    "            spectral_centroid, \n",
    "            spectral_bandwidth,\n",
    "            spectral_rolloff,\n",
    "            zcr,\n",
    "            chroma\n",
    "        ], axis=0)\n",
    "        \n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract features with improved batch size\n",
    "def extract_features_batch(metadata_df, batch_size=64, max_pad_len=64): \n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, len(metadata_df), batch_size):\n",
    "        batch_end = min(i + batch_size, len(metadata_df))\n",
    "        batch = metadata_df.iloc[i:batch_end]\n",
    "        \n",
    "        print(f\"Processing batch {i//batch_size + 1}/{(len(metadata_df)-1)//batch_size + 1}\")\n",
    "        \n",
    "        batch_features = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for _, row in batch.iterrows():\n",
    "            features = extract_features(row['file_path'], max_pad_len)\n",
    "            if features is not None:\n",
    "                batch_features.append(features)\n",
    "                batch_labels.append(row['emotion_label'])\n",
    "        \n",
    "        # Add batch data to all data\n",
    "        all_features.extend(batch_features)\n",
    "        all_labels.extend(batch_labels)\n",
    "\n",
    "        import gc\n",
    "        gc.collect()\n",
    "    \n",
    "    return np.array(all_features), all_labels\n",
    "\n",
    "# Execute feature extraction\n",
    "print(\"Extracting features in batches...\")\n",
    "features, labels = extract_features_batch(metadata_df)\n",
    "\n",
    "# Reshape features for CNN model\n",
    "features_reshaped = features.reshape(features.shape[0], features.shape[1], features.shape[2], 1)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_onehot = tf.keras.utils.to_categorical(labels_encoded)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Detected {num_classes} emotion classes: {label_encoder.classes_}\")\n",
    "\n",
    "# Split data with stratification for balanced sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_reshaped, labels_onehot, test_size=0.15, random_state=42, stratify=labels_onehot\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.15, random_state=42, stratify=y_train\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize features to improve training\n",
    "def preprocess_features(features_train, features_val, features_test):\n",
    "    # Reshape for normalization\n",
    "    n_samples, n_features, n_timesteps, n_channels = features_train.shape\n",
    "    features_train_reshaped = features_train.reshape(n_samples, -1)\n",
    "    \n",
    "    # Fit normalizer on training data\n",
    "    normalizer = StandardScaler()\n",
    "    features_train_normalized = normalizer.fit_transform(features_train_reshaped)\n",
    "    \n",
    "    features_train_normalized = features_train_normalized.reshape(n_samples, n_features, n_timesteps, n_channels).astype(np.float32)\n",
    "    \n",
    "    if features_val is not None:\n",
    "        n_val = features_val.shape[0]\n",
    "        features_val_reshaped = features_val.reshape(n_val, -1)\n",
    "        features_val_normalized = normalizer.transform(features_val_reshaped)\n",
    "        features_val_normalized = features_val_normalized.reshape(n_val, n_features, n_timesteps, n_channels).astype(np.float32)\n",
    "    else:\n",
    "        features_val_normalized = None\n",
    "        \n",
    "    if features_test is not None:\n",
    "        n_test = features_test.shape[0]\n",
    "        features_test_reshaped = features_test.reshape(n_test, -1)\n",
    "        features_test_normalized = normalizer.transform(features_test_reshaped)\n",
    "        features_test_normalized = features_test_normalized.reshape(n_test, n_features, n_timesteps, n_channels).astype(np.float32)\n",
    "    else:\n",
    "        features_test_normalized = None\n",
    "        \n",
    "    return features_train_normalized, features_val_normalized, features_test_normalized, normalizer\n",
    "\n",
    "# Disable mixed precision to ensure data type consistency\n",
    "tf.keras.mixed_precision.set_global_policy('float32')\n",
    "print(\"Mixed precision disabled for data type consistency\")\n",
    "\n",
    "# Reprocess features with proper data type\n",
    "X_train_norm, X_val_norm, X_test_norm, normalizer = preprocess_features(X_train, X_val, X_test)\n",
    "\n",
    "print(f\"Training set: {X_train_norm.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val_norm.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test_norm.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape, dtype=tf.float32)\n",
    "    \n",
    "    # First block\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Store the shape before second block for proper residual shape matching\n",
    "    skip_shape = x.shape[1:3]  # Get spatial dimensions\n",
    "    \n",
    "    # Second block with proper residual connection\n",
    "    # Apply convolution before residual branch to ensure same shapes later\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # Create residual connection with matching shapes\n",
    "    residual = layers.Conv2D(64, (1, 1), padding='same')(x)\n",
    "    residual = layers.BatchNormalization()(residual)\n",
    "    \n",
    "    # Continue with main path\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # Apply pooling to both paths using same parameters\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    residual = layers.MaxPooling2D((2, 2))(residual)\n",
    "    \n",
    "    # Now shapes should match for the addition\n",
    "    x = layers.add([x, residual])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Third block\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Classification layers with proper regularization\n",
    "    x = layers.Dense(256, kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = layers.Dense(128, kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    # Output layer with proper initialization\n",
    "    outputs = layers.Dense(\n",
    "        num_classes, \n",
    "        activation='softmax',\n",
    "        kernel_initializer=tf.keras.initializers.HeNormal(seed=42),\n",
    "        bias_initializer=tf.keras.initializers.Zeros()\n",
    "    )(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    # Add missing import for Keras backend\n",
    "    from tensorflow.keras import backend as K\n",
    "    \n",
    "    # Use Adam with optimized parameters\n",
    "    optimizer = optimizers.Adam(\n",
    "        learning_rate=1e-3, # Initial learning rate\n",
    "        beta_1=0.9, # Adam beta_1\n",
    "        beta_2=0.999, # Adam beta_2\n",
    "        epsilon=1e-08, # Adam epsilon\n",
    "        clipnorm=1.0,  # Gradient clipping to prevent exploding gradients\n",
    "    )\n",
    "    \n",
    "    # Use CategoricalCrossentropy with label smoothing for better generalization\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to check dataset balance\n",
    "def check_dataset_balance(labels):    \n",
    "    counts = np.sum(labels, axis=0)\n",
    "    for i, count in enumerate(counts):        \n",
    "        print(f\"Class {i}: {count} samples\")\n",
    "    if np.std(counts) / np.mean(counts) > 0.1:\n",
    "        print(\"WARNING: Dataset is imbalanced. Consider resampling or stronger class weights.\")\n",
    "    return counts\n",
    "\n",
    "# Rebalance training data if needed\n",
    "def balance_dataset(X, y, upsample=True):\n",
    "    \"\"\"Balance the dataset by either upsampling minority classes or downsampling majority classes\"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    n_classes = y.shape[1]\n",
    "    class_counts = np.sum(y, axis=0)\n",
    "    \n",
    "    # Check if we need balancing\n",
    "    if np.max(class_counts) / np.min(class_counts) < 1.2:\n",
    "        print(\"Dataset is already reasonably balanced\")\n",
    "        return X, y\n",
    "    \n",
    "    # Calculate target count per class\n",
    "    if upsample:\n",
    "        # Upsample to the maximum class count\n",
    "        target_count = int(np.max(class_counts))  # Convert to integer\n",
    "        print(f\"Upsampling all classes to {target_count} samples\")\n",
    "    else:\n",
    "        # Downsample to the minimum class count\n",
    "        target_count = int(np.min(class_counts))  # Convert to integer\n",
    "        print(f\"Downsampling all classes to {target_count} samples\")\n",
    "    \n",
    "    balanced_X = []\n",
    "    balanced_y = []\n",
    "    \n",
    "    # Process each class\n",
    "    for class_idx in range(n_classes):\n",
    "        # Get samples of this class\n",
    "        class_indices = np.where(np.argmax(y, axis=1) == class_idx)[0]\n",
    "        class_samples_X = X[class_indices]\n",
    "        class_samples_y = y[class_indices]\n",
    "        \n",
    "        current_count = len(class_indices)\n",
    "        \n",
    "        if current_count < target_count:\n",
    "            # Need to upsample\n",
    "            # Number of times to replicate the entire class set\n",
    "            n_repeats = target_count // current_count  # Integer division\n",
    "            remainder = target_count % current_count   # Integer remainder\n",
    "            \n",
    "            # Add complete copies\n",
    "            for _ in range(n_repeats):\n",
    "                balanced_X.append(class_samples_X)\n",
    "                balanced_y.append(class_samples_y)\n",
    "            # Add the remainder samples\n",
    "            if remainder > 0:\n",
    "                # Randomly select 'remainder' samples\n",
    "                idx = np.random.choice(current_count, remainder, replace=False)\n",
    "                balanced_X.append(class_samples_X[idx])\n",
    "                balanced_y.append(class_samples_y[idx])\n",
    "        elif current_count > target_count:\n",
    "            # Need to downsample\n",
    "            # Randomly select 'target_count' samples\n",
    "            idx = np.random.choice(current_count, target_count, replace=False)\n",
    "            balanced_X.append(class_samples_X[idx])\n",
    "            balanced_y.append(class_samples_y[idx])\n",
    "        else:\n",
    "            # Already at target count\n",
    "            balanced_X.append(class_samples_X)\n",
    "            balanced_y.append(class_samples_y)\n",
    "    \n",
    "    # Combine and shuffle the balanced data\n",
    "    balanced_X = np.vstack(balanced_X).astype(np.float32)  # Ensure correct dtype\n",
    "    balanced_y = np.vstack(balanced_y).astype(np.float32)  # Ensure correct dtype\n",
    "    \n",
    "    # Shuffle the data\n",
    "    indices = np.random.permutation(len(balanced_X))\n",
    "    balanced_X = balanced_X[indices]\n",
    "    balanced_y = balanced_y[indices]\n",
    "    \n",
    "    print(f\"Balanced dataset shape: {balanced_X.shape}, {balanced_y.shape}\")\n",
    "    return balanced_X, balanced_y\n",
    "\n",
    "# Balance the training data to avoid bias\n",
    "print(\"Checking training data balance...\")\n",
    "check_dataset_balance(y_train)\n",
    "X_train_balanced, y_train_balanced = balance_dataset(X_train_norm, y_train, upsample=True)\n",
    "\n",
    "# Verify the balanced data\n",
    "print(\"After balancing:\")\n",
    "check_dataset_balance(y_train_balanced)\n",
    "\n",
    "# Create a fresh model with the new architecture\n",
    "input_shape = X_train_balanced.shape[1:]\n",
    "model = create_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# simple_data_generator function to yield batches of data\n",
    "def simple_data_generator(X, y, batch_size=32, augment=True):\n",
    "    num_samples = X.shape[0]\n",
    "    \n",
    "    while True:\n",
    "        # Shuffle indices for each epoch\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices[i:min(i + batch_size, num_samples)]\n",
    "            batch_X = X[batch_indices].copy()\n",
    "            batch_y = y[batch_indices]\n",
    "            \n",
    "            # Enhanced augmentation techniques\n",
    "            if augment:\n",
    "                for j in range(len(batch_X)):\n",
    "                    # Apply augmentation with probability\n",
    "                    if np.random.random() < 0.5:\n",
    "                        # Randomly select augmentation techniques\n",
    "                        aug_type = np.random.choice(['time_mask', 'freq_mask', 'both', 'noise'])\n",
    "                        \n",
    "                        if aug_type == 'time_mask' or aug_type == 'both':\n",
    "                            # Time masking\n",
    "                            time_mask_size = np.random.randint(2, 8)  # Increased max mask size\n",
    "                            time_start = np.random.randint(0, batch_X[j].shape[1] - time_mask_size)\n",
    "                            batch_X[j, :, time_start:time_start + time_mask_size, :] = 0\n",
    "                        \n",
    "                        if aug_type == 'freq_mask' or aug_type == 'both':\n",
    "                            # Frequency masking\n",
    "                            freq_mask_size = np.random.randint(2, 6)  # Increased max mask size\n",
    "                            freq_start = np.random.randint(0, batch_X[j].shape[0] - freq_mask_size)\n",
    "                            batch_X[j, freq_start:freq_start + freq_mask_size, :, :] = 0\n",
    "                            \n",
    "                        if aug_type == 'noise':\n",
    "                            # Add small random noise\n",
    "                            noise_level = np.random.uniform(0.001, 0.02)\n",
    "                            noise = np.random.normal(0, noise_level, batch_X[j].shape)\n",
    "                            batch_X[j] = batch_X[j] + noise\n",
    "                            \n",
    "                        # Random scaling (slight volume changes)\n",
    "                        if np.random.random() < 0.3:\n",
    "                            scale_factor = np.random.uniform(0.8, 1.2)\n",
    "                            batch_X[j] = batch_X[j] * scale_factor\n",
    "            \n",
    "            yield batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set up more effective callbacks\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=40, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Improved learning rate scheduler\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2, \n",
    "    patience=5,   \n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class CyclicLR(callbacks.Callback):\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "\n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "        if self.clr_iterations == 0:\n",
    "            self.model.optimizer.learning_rate.assign(self.base_lr)\n",
    "        else:\n",
    "            self.model.optimizer.learning_rate.assign(self.clr())\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "        \n",
    "        try:\n",
    "            current_lr = float(self.model.optimizer.learning_rate.numpy())\n",
    "        except:\n",
    "            try:\n",
    "                current_lr = K.get_value(self.model.optimizer.learning_rate)\n",
    "            except:\n",
    "                current_lr = self.clr()\n",
    "        \n",
    "        self.history.setdefault('lr', []).append(current_lr)\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        # Update the optimizer's learning rate\n",
    "        self.model.optimizer.learning_rate.assign(self.clr())\n",
    "\n",
    "# Apply cyclic learning rate\n",
    "step_size = 8 * (len(X_train_balanced) // 32) \n",
    "clr = CyclicLR(\n",
    "    base_lr=1e-4,\n",
    "    max_lr=1e-2,\n",
    "    step_size=step_size,\n",
    "    mode='triangular2'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Simple generator for training without class weights\n",
    "train_gen = simple_data_generator(X_train_balanced, y_train_balanced, batch_size=32, augment=True)\n",
    "validation_gen = simple_data_generator(X_val_norm, y_val, batch_size=32, augment=False)\n",
    "\n",
    "# Calculate steps\n",
    "steps_per_epoch = max(1, len(X_train_balanced) // 32)\n",
    "validation_steps = max(1, len(X_val_norm) // 32)\n",
    "\n",
    "# Restart training with a completely new approach\n",
    "print(\"Starting training with tuned hyperparameters...\")\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=150, \n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping, reduce_lr, clr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# After training, evaluate the model on test data\n",
    "print(\"\\nEvaluating model on test data...\")\n",
    "y_pred_prob = model.predict(X_test_norm)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a detailed confusion matrix\n",
    "def plot_detailed_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Plot the confusion matrix with better styling\n",
    "    ax = sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "                    xticklabels=class_names, yticklabels=class_names,\n",
    "                    linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "    \n",
    "    # Add counts to the cells as well as percentages\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            text = plt.text(j + 0.5, i + 0.7, f\"({cm[i, j]})\", \n",
    "                           ha=\"center\", va=\"center\", color=\"darkred\" if cm_normalized[i, j] < 0.5 else \"white\", \n",
    "                           fontsize=9)\n",
    "    plt.title('Confusion Matrix (Normalized)', fontsize=16, pad=20)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_detailed.png')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the detailed confusion matrix\n",
    "plot_detailed_confusion_matrix(y_true, y_pred, label_encoder.classes_)\n",
    "\n",
    "# 3. Add a learning curve plot to see training progress\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy learning curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Accuracy Learning Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Plot loss learning curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Loss Learning Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('learning_curves.png')\n",
    "plt.show()\n",
    "\n",
    "# Save model artifacts\n",
    "model.save('improved_emotion_recognition_model.h5')\n",
    "\n",
    "with open('feature_normalizer.pkl', 'wb') as f:\n",
    "    pickle.dump(normalizer, f)\n",
    "\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "print(\"Enhanced model and preprocessing tools saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
